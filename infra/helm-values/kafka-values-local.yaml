# Single-node, controller+broker in one pod; plaintext listeners; single-node-friendly internals.

listeners:
  client: {protocol: PLAINTEXT, containerPort: 9092, name: CLIENT}
  controller: {protocol: PLAINTEXT, containerPort: 9093, name: CONTROLLER}
  interbroker: {protocol: PLAINTEXT, containerPort: 9094, name: INTERNAL}

controller:
  livenessProbe:
    enabled: true
    initialDelaySeconds: 90       # give JVM + log init some slack
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 12          # ~2 minutes before restart
    successThreshold: 1

    # Fast to remove from Service while starting/loaded, but never restarts the pod
  readinessProbe:
    enabled: true
    initialDelaySeconds: 20
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6           # ~1 minute to go NotReady
    successThreshold: 1

    # Crucial after unclean shutdowns / metadata log recovery
  startupProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 45          # ~7.5 minutes boot window
    successThreshold: 1
  replicaCount: 1
  controllerOnly: false
  # âœ… Resources for the Kafka container (fix OOMKills)
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: "1"
      memory: 2Gi
  extraEnv:
    - name: KAFKA_HEAP_OPTS
      value: "-Xms1200m -Xmx1200m"        # heap < limit to avoid OOM
    - name: KAFKA_JVM_PERFORMANCE_OPTS
      value: "-XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:+ExplicitGCInvokesConcurrent"
  overrideConfiguration:
    # Roles & listeners
    auto.create.topics.enable: false
    process.roles: controller,broker
    controller.listener.names: CONTROLLER
    inter.broker.listener.name: INTERNAL
    listeners: CLIENT://:9092,INTERNAL://:9094,CONTROLLER://:9093
    listener.security.protocol.map: CLIENT:PLAINTEXT,INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
    advertised.listeners: >
      CLIENT://kafka.payment.svc.cluster.local:9092,
      INTERNAL://kafka-controller-0.kafka-controller-headless.payment.svc.cluster.local:9094

    # Single-node defaults (safe in dev)
    num.partitions: 1
    min.insync.replicas: 1

    # Make internal topics 1/1 so Kafka won't expect a 3-node quorum
    offsets.topic.replication.factor: 1
    offsets.topic.num.partitions: 1
    transaction.state.log.replication.factor: 1
    transaction.state.log.min.isr: 1
    transaction.state.log.num.partitions: 1
    # Kafka 4.x also logs this one; keep it small in single node
    share.coordinator.state.topic.num.partitions: 1
    log.retention.bytes: 268435456         # 256 MiB total per log (delete old)
    log.retention.hours: 2                  # or use minutes for tighter control
    log.segment.bytes: 67108864             # 64 MiB segments (fewer big mmaps)
    log.cleaner.enable: "true"
    cleanup.policy: delete

  # (optional) avoid huge fetch/produce batches in dev
    replica.fetch.max.bytes: 1048576        # 1 MiB
    message.max.bytes: 1048576              # 1 MiB
    fetch.message.max.bytes: 1048576

broker:
  # No separate broker-only set for single-node
  replicaCount: 0

# Avoid surprises with policies in local clusters
networkPolicy:
  enabled: false

metrics:
  kafka:
    enabled: false
defaultInitContainers:
  prepareConfig:
    resources:
      requests: {cpu: 50m, memory: 64Mi}
      limits: {cpu: 200m, memory: 128Mi}